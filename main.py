{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import pdb\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "from opts import parser\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from utils import read_mapping_dict\n",
    "from data.basedataset import BaseDataset\n",
    "from model.futr import FUTR\n",
    "from train import train\n",
    "from predict import predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.cpu:\n",
    "        device = torch.device('cpu')\n",
    "        print('using cpu')\n",
    "    else:\n",
    "        device = torch.device('cuda')\n",
    "        print('using gpu')\n",
    "    print('runs : ', args.runs)\n",
    "    print('model type : ', args.model)\n",
    "    print('input type : ', args.input_type)\n",
    "    print('Epoch : ', args.epochs)\n",
    "    print(\"batch size : \", args.batch_size)\n",
    "    print(\"Split : \", args.split)\n",
    "\n",
    "    dataset = args.dataset\n",
    "    task = args.task\n",
    "    split = args.split\n",
    "\n",
    "    if dataset == 'breakfast':\n",
    "        data_path = './datasets/breakfast'\n",
    "    elif dataset == '50salads' :\n",
    "        data_path = './datasets/50salads'\n",
    "\n",
    "    mapping_file = os.path.join(data_path, 'mapping.txt')\n",
    "    actions_dict = read_mapping_dict(mapping_file)\n",
    "    video_file_path = os.path.join(data_path, 'splits', 'train.split'+args.split+'.bundle' )\n",
    "    video_file_test_path = os.path.join(data_path, 'splits', 'test.split'+args.split+'.bundle' )\n",
    "\n",
    "    video_file = open(video_file_path, 'r')\n",
    "    video_file_test = open(video_file_test_path, 'r')\n",
    "\n",
    "    video_list = video_file.read().split('\\n')[:-1]\n",
    "    video_test_list = video_file_test.read().split('\\n')[:-1]\n",
    "\n",
    "    features_path = os.path.join(data_path, 'features')\n",
    "    gt_path = os.path.join(data_path, 'groundTruth')\n",
    "\n",
    "    n_class = len(actions_dict) + 1\n",
    "    pad_idx = n_class + 1\n",
    "\n",
    "    # Model specification\n",
    "    model = FUTR(n_class, args.hidden_dim, device=device, args=args, src_pad_idx=pad_idx,\n",
    "                            n_query=args.n_query, n_head=args.n_head,\n",
    "                            num_encoder_layers=args.n_encoder_layer, num_decoder_layers=args.n_decoder_layer).to(device)\n",
    "\n",
    "    model_save_path = os.path.join('./save_dir', args.dataset, args.task, 'model/transformer', split, args.input_type, \\\n",
    "                                    'runs'+str(args.runs))\n",
    "    results_save_path = os.path.join('./save_dir/'+args.dataset+'/'+args.task+'/results/transformer', 'split'+split,\n",
    "                                    args.input_type )\n",
    "    if not os.path.exists(results_save_path):\n",
    "        os.makedirs(results_save_path)\n",
    "\n",
    "    model_save_file = os.path.join(model_save_path, 'checkpoint.ckpt')\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
    "    warmup_epochs = args.warmup_epochs\n",
    "    scheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs=warmup_epochs, max_epochs=args.epochs)\n",
    "    criterion = nn.MSELoss(reduction = 'none')\n",
    "\n",
    "    if args.predict :\n",
    "        obs_perc = [0.2, 0.3]\n",
    "        results_save_path = results_save_path +'/runs'+ str(args.runs) +'.txt'\n",
    "        if args.dataset == 'breakfast' :\n",
    "            model_path = './ckpt/bf_split'+args.split+'.ckpt'\n",
    "        elif args.dataset == '50salads':\n",
    "            model_path = './ckpt/50s_split'+args.split+'.ckpt'\n",
    "        print(\"Predict with \", model_path)\n",
    "\n",
    "        for obs_p in obs_perc :\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.to(device)\n",
    "            predict(model, video_test_list, args, obs_p, n_class, actions_dict, device)\n",
    "    else :\n",
    "        # Training\n",
    "        trainset = BaseDataset(video_list, actions_dict, features_path, gt_path, pad_idx, n_class, n_query=args.n_query, args=args)\n",
    "        train_loader = DataLoader(trainset, batch_size=args.batch_size, \\\n",
    "                                                    shuffle=True, num_workers=args.workers,\n",
    "                                                    collate_fn=trainset.my_collate)\n",
    "        train(args, model, train_loader, optimizer, scheduler, criterion,\n",
    "                     model_save_path, pad_idx, device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
